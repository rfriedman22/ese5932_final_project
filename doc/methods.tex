\documentclass[12pt]{article}
%\usepackage[latin1]{inputenc}
\usepackage{pdfsync}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{latexsym}
\usepackage{amsthm}
\usepackage{hyperref}
\usepackage{eucal}
\usepackage{indentfirst}
\usepackage[pdftex]{graphicx}
\usepackage{amsfonts}
\usepackage{natbib}
\usepackage{sidecap}
\usepackage{subfigure}
\usepackage{setspace}
\usepackage{fancyhdr}
\usepackage{gensymb}
\usepackage{color}
\usepackage{wrapfig}
\usepackage{array}
\usepackage{booktabs}
\usepackage{lastpage}
\usepackage[titletoc]{appendix}
\usepackage{soul}
\usepackage{pythontex}
%\usepackage{ulem}
\usepackage[body={9.0in, 9.0in},left=1 in,right=1in]{geometry} % Geometry package for easy page margin setup\setcounter{MaxMatrixCols}{30}
\linespread{1} % interline
\DeclareGraphicsExtensions{.jpg,.pdf,.mps,.png,.eps}
 

%%%%%%%%%%%%%Colors%%%%%%%%%%%%%%%
\usepackage[dvispnames]{xcolor}
\definecolor{pink}{cmyk}{0, 0.7808, 0.4429, 0.1412}
%%%%%%%%%%%%% Page setup %%%%%%%%%%
\pagestyle{fancy}
\renewcommand{\headrulewidth}{0pt}
%\lhead{\footnotesize \parbox{11cm}{Draft 1} }
\lfoot{\footnotesize Siqi Zhao\\ szhao@wustl.edu}
%\cfoot{}
%\chead{}
%\rhead{\footnotesize 3}
\rfoot{\footnotesize Page \thepage\ of \pageref{LastPage}}
\newcommand{\noin}{\noindent} 


%%%%%%%%%%%%%%%%%%%%%%%%
%\usepackage{pythonhighlight}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother
\usepackage{physics}
%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}


\section{Methods}

\noin As we know from the physics of computed tomography, the measured sinogram image is convolved with several sources of noise, notably electronic noise and structural noise\cite{Duan2013-mi}. Hence, using an iterative method that handles noise is necessary. In formulating the CT reconstruction as an optimization problem, one of the important considerations is to find a regularization method for the ill-posed problem that preserves the edges in the true image, since identifying boundaries of objects (such as the boundary between normal and abnormal tissues) has high diagnostic value.

\vspace{0.2in}

\noin We decided to follow the fast gradient-based algorithm proposed by Beck and Teboulle\cite{Beck2009-id}, and the following section will discuss the specific implementation of their method for CT image reconstruction.

\vspace{0.2in}

\noin Specifically, we chose isotropic TV regularization\footnote{In our presentation, we claimed that we were using the anisotropic TV because we falsely assumed that we were optimizing an 1D vector rather than a 2D image. For the 1D case, isotropic and anisotropic TV are essentially the same. The error was resulted from the fact that the majority of the group members are not in the field of imaging science as are unfamiliar with how matlab implicitly handles an image. And the error of assuming a 1D vector resulted in thinking we can use anisotropic TV as well as creating vertical artifacts in reconstructed images, we have corrected the errors in the implementation and rewritten this section. This has been a good learning opportunity for us both in terms of learning new knowledge as well as learning the process of gaining such knowledge from outside of the field. We also attempted to rewrite the method section to increase clarity, we would appreciate any feedback on this version of the description of the method.}. The original publication of FISTA with TV\cite{Beck2009-id} describes two types of TV regularization, anisotropic and isotropic TV, and the specific python package of choice, pyunloc\cite{pyunlocbox}, implements isotropic TV functionals. We decided to use the implemented TV function in the package and conducted some research on the differences of those two types of TV regularization functions. As being described in \cite{Condat2017-uj}, anisotropic TV is known to favor horizontal and vertical structures for 2D images, and isotropic TV is shown to be a superior choice for regularization for a 2D image that preserves the off-axis edges. 

\vspace{0.2in}

\noin The optimization problem can be formulated as:
\begin{align}
 \underset{x}{min}\{ ||A(x) - d||^2 + 2 \lambda\text{TV}(x)\} \label{eq1}
\end{align}

\noin where
$x \in \mathbb{R}^{m \times 1}$ is the flattened true image with the size $\sqrt{m \times 1}$.
$d \in \mathbb{R}^n$ is the flattened sinogram image where $ |rays|\times|views| = n$.
$A \in \mathbb{R}^{m \times n}$ is the forward operator that transforms an image to a sinogram image.
$\lambda$ is the regularization parameter. 
$\text{TV}(x): \mathbb{R}^{m\times 1} \rightarrow \mathbb{R}$  is an istropic total variation functional, where 
\begin{align}
    x \in \mathbb{R}^{m\times 1}, \text{TV}(x) = \sum_{i=1}^{m-1}{|x_i - x_{i+1}|} 
\end{align}

\noin To solve the problem in eq.\ref{eq1}, it requires a method that sovles non-differentiable optimization problems. As discussed in \cite{Beck2009-id}, the gradient projection method is particularly suited for this task because of the faster convergence rate compare to other methods such as primal-dual Newton-based methods\cite{Chan1996-mt}. The specific innovation of \cite{Beck2009-id} is a new proximal gradient method called fast iterative shrinkage/thresholding algorithm (FISTA), which has a global convergence rate of $\mathcal{O}(\frac{1}{k^2})$ (The proof of convergence rate is detailed in \cite{Beck2009-id}). 

\vspace{0.2in}

\noin The general principle of the algorithm will be discussed in this paragraph and the pseudocode for the specific implementation will follow. The first key insight is the construction of the new FISTA term. 

\noin The general principle of the algorithm will be discussed in this paragraph and the pseudocode for the specific implementation will follow. The first key insight is to apply a orthogonal projection operator $\text{P}_C$, which is a box projection that maps $x$ onto a feasible set which ensures the smoothness of the eq.\ref{eq1} in the projected space. As discussed in \cite{Beck2009-id}, the solution is
\begin{align}
    x_k = \text{P}_C(x_{k-1} - t_k\nabla f(x_{k-1}))
\end{align}

\noin where $f$ denotes the data fidelity term $\underset{x}{min}\{ ||A(x) - d||^2$.

\vspace{0.2in}

\noin The next step is to construct the proximal map. Let $\mathcal{P}_1$ denote the set of all pairs of matrices $(\mathbf{p}, \mathbf{q})$. Note that for our special case where $x \in \mathbb{R}^{m \times 1}$, $\mathcal{P}_1$ becomes matrices $\mathbf{p}$ satisfying
\begin{align}
    |p_i| \leq 1, i = 1,\cdots,m-1
\end{align}

\noin Following \emph{Proposition 4.1} in \cite{Beck2009-id}, we can write out the objective function as 
\begin{align}
\underset{\mathbf{p} \in \mathcal{P}}{max} \underset{x \in \text{C}}{min}\{||x-d|||_\text{F}^2 + 2\lambda\text{Tr}(\mathcal{L}(\mathbf{p}^{\text{T}}x))\}
\end{align}

\noin and the optimal solution of the inner minimization problem is 
\begin{align}
    x = \text{P}_C(d - \lambda \mathcal{L}(\mathbf{p}))
\end{align}

\noin where $\mathcal{L}: \mathbb{R}^{(m-1)\times 1} \rightarrow \mathbb{R}^{m\times 1}$ is a linear operator defined by
\begin{align}
    \mathcal{L}(\mathbf{p})_{i} = p_i - p_{i-1}, i= 1,\cdots,m-1
\end{align}

\noin Plugging in the objective function, gradient and step size (which is an upper bound on the Lipschitz constant, and in term depends on the regularization parameter), we can write out the pseudocode for the algorithm, see algorithm.\ref{euclid}. 

\vspace{0.1in}

\noin We found an existing package in python called pyunlocbox \cite{pyunlocbox} to implement the algorithm. This package has all the required components for constructing the functions for data fidelity and regularization terms, and has implemented the FISTA version. 

\begin{algorithm}
\caption{TV-FISTA}\label{euclid}
    \begin{algorithmic}
    \State \textbf{Input} $d$, $A$, $\lambda$, $maxiter$, $tol$
    \State $r_0 = p_0 = 0_{m-1}$, $t_1 = 1$
    \If {$i \leq maxiter$}
    \BState \emph{Forward}
    \State \textbf{Compute} $x_f = \frac{2}{\lambda}A^{T}(A(x)-d)$
    \BState \emph{Backward}
    \State $x_i = x_f - \frac{1}{\lambda} \div x_f$
    \State $obj = \frac{1}{2}||x_f -x_i ||^2 + \lambda ||\nabla x_i||^2$
    \State $tol_i = \frac{|obj_{i-1} - obj_i|}{obj_i}$
    \BState \emph{Update projector}
    \State $r_i = r - \frac{1}{8 \lambda} \nabla x_i$
    \BState \emph{FISTA}
    \State $t_{i+1} = \frac{1 + \sqrt{1 + 4 t_{i}^2}}{2}$
    \State $p_i = \frac{r_1}{\text{max}\{1, p_i\}}$
    \State $r_i = p_i + \frac{t_i -1}{t_i * (p_i - p_{i-1})}$
    \If {$tol_i \leq tol$}
        \State \textbf{Stop}
    \EndIf
    \State $i = i +1$
    \EndIf 
\end{algorithmic}
\end{algorithm}

\noin Now we discuss other implementation choices in this algorithm. First, we decided to use relative tolerance as our stopping criterion since it is easy to implement and measures the change in value relative to the size of the values themselves. Second, we used L-curve criterion to decide the regularization parameter, because it gives us a principled way to decide the proper amount of regularization without relying on the reference image. 

\vspace{0.2in}
\noin In general, we made an iterative plan for implementing this algorithm. We started from a series of simple choices, such as optimizing in the image domain with image represented as a row vector (in contrast to wavelet domain), the anisotropic TV, and relative tolerance. While those choices are unsophisticated compare to many advanced tools, we reasoned that we could adjust our implementation choices if the reconstruction quality is poor. To our surprise and delight, the first try of the reconstruction quality is good. We hence adhered to our implementation choices in regularization function and stopping criterion. The detailed reconstruction result will be presented in the result section. 

%\bibliography{ref}{}
%\bibliographystyle{plain}

\end{document}